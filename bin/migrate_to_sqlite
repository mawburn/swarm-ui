#!/usr/bin/env ruby
# frozen_string_literal: true

# This migration script requires both pg and sqlite3 gems
# Use the temporary Gemfile.migrate if running this script
# Example: BUNDLE_GEMFILE=Gemfile.migrate bundle exec bin/migrate_to_sqlite

require_relative "../config/environment"
require "fileutils"
require "json"

class PostgresqlToSqliteMigrator
  def initialize
    # Hardcode PostgreSQL configuration for export
    @pg_config = {
      "adapter" => "postgresql",
      "encoding" => "unicode",
      "pool" => ENV.fetch("RAILS_MAX_THREADS") { 5 },
      "username" => "swarm_ui",
      "password" => "swarm_ui",
      "host" => "127.0.0.1",
      "port" => ENV.fetch("POSTGRES_PORT", "5432"),
      "database" => "swarm_ui_#{Rails.env}"
    }
    @sqlite_path = Rails.root.join("storage", "#{Rails.env}.sqlite3")
    @backup_path = Rails.root.join("tmp", "pg_backup_#{Time.now.strftime('%Y%m%d_%H%M%S')}.json")
  end

  def migrate!
    puts "Starting migration from PostgreSQL to SQLite..."
    
    # Step 1: Export data from PostgreSQL
    export_data
    
    # Step 2: Prepare SQLite database
    prepare_sqlite_database
    
    # Step 3: Import data into SQLite
    import_data
    
    puts "Migration completed successfully!"
    puts "SQLite database created at: #{@sqlite_path}"
    puts "Backup saved at: #{@backup_path}"
  end

  private

  def export_data
    puts "Exporting data from PostgreSQL..."
    
    # Establish connection to PostgreSQL for export
    ActiveRecord::Base.establish_connection(@pg_config)
    
    data = {}
    
    # Export all tables except schema_migrations and ar_internal_metadata
    tables_to_export.each do |table|
      puts "  Exporting #{table}..."
      # Use select_all to get proper hash format
      result = ActiveRecord::Base.connection.select_all("SELECT * FROM #{table}")
      data[table] = result.to_a
      puts "    Exported #{data[table].size} records"
    end
    
    # Save backup
    FileUtils.mkdir_p(File.dirname(@backup_path))
    File.write(@backup_path, JSON.pretty_generate(data))
    
    puts "Data exported to #{@backup_path}"
  end

  def prepare_sqlite_database
    puts "Preparing SQLite database..."
    
    # Ensure storage directory exists with proper permissions
    storage_dir = File.dirname(@sqlite_path)
    FileUtils.mkdir_p(storage_dir)
    FileUtils.chmod(0755, storage_dir)
    
    # Remove existing SQLite databases if they exist
    Dir[Rails.root.join("storage", "*.sqlite3")].each do |file|
      puts "  Removing existing database: #{File.basename(file)}"
      FileUtils.rm_f(file)
    end
    
    # Update database configuration temporarily
    sqlite_config = {
      "adapter" => "sqlite3",
      "database" => @sqlite_path.to_s,
      "pool" => @pg_config["pool"] || 5,
      "timeout" => 5000
    }
    
    # Create SQLite database with schema
    puts "Creating SQLite database schema..."
    ActiveRecord::Base.establish_connection(sqlite_config)
    
    # Create a modified schema without PostgreSQL extensions
    create_sqlite_schema
  end

  def create_sqlite_schema
    ActiveRecord::Schema[8.0].define(version: 2025_07_26_012245) do
      create_table "github_webhook_events", force: :cascade do |t|
        t.bigint "project_id", null: false
        t.string "event_type"
        t.boolean "enabled", default: true
        t.datetime "created_at", null: false
        t.datetime "updated_at", null: false
        t.index ["project_id"], name: "index_github_webhook_events_on_project_id"
      end

      create_table "github_webhook_processes", force: :cascade do |t|
        t.bigint "project_id", null: false
        t.integer "pid"
        t.string "status"
        t.datetime "started_at"
        t.datetime "stopped_at"
        t.datetime "created_at", null: false
        t.datetime "updated_at", null: false
        t.index ["project_id"], name: "index_github_webhook_processes_on_project_id"
      end

      create_table "instance_templates", force: :cascade do |t|
        t.string "name", null: false
        t.text "description"
        t.string "model"
        t.string "provider"
        t.text "prompt"
        t.string "directory"
        t.json "tools"
        t.json "allowed_tools"
        t.json "disallowed_tools"
        t.boolean "worktree", default: false
        t.boolean "vibe", default: false
        t.float "temperature"
        t.string "api_version"
        t.string "reasoning_effort"
        t.datetime "created_at", null: false
        t.datetime "updated_at", null: false
        t.index ["name"], name: "index_instance_templates_on_name"
      end

      create_table "projects", force: :cascade do |t|
        t.string "name", null: false
        t.string "path", null: false
        t.string "vcs_type"
        t.string "default_config_path"
        t.boolean "default_use_worktree", default: false
        t.boolean "archived", default: false
        t.datetime "last_session_at"
        t.integer "total_sessions_count", default: 0
        t.integer "active_sessions_count", default: 0
        t.text "environment_variables"
        t.json "preferred_models", default: {}
        t.datetime "created_at", null: false
        t.datetime "updated_at", null: false
        t.boolean "github_webhook_enabled", default: false
        t.string "github_repo_owner"
        t.string "github_repo_name"
        t.index ["archived"], name: "index_projects_on_archived"
        t.index ["path"], name: "index_projects_on_path", unique: true
      end

      create_table "sessions", force: :cascade do |t|
        t.string "session_id", null: false
        t.string "swarm_name"
        t.string "project_folder_name"
        t.datetime "started_at"
        t.datetime "ended_at"
        t.integer "duration_seconds"
        t.string "status"
        t.text "configuration"
        t.string "configuration_path"
        t.json "metadata"
        t.datetime "created_at", null: false
        t.datetime "updated_at", null: false
        t.boolean "use_worktree", default: false, null: false
        t.string "session_path", null: false
        t.datetime "resumed_at"
        t.text "environment_variables"
        t.bigint "project_id", null: false
        t.text "initial_prompt"
        t.integer "github_issue_number"
        t.integer "github_pr_number"
        t.string "github_issue_type"
        t.index ["project_id", "github_issue_number"], name: "index_sessions_on_project_id_and_github_issue_number"
        t.index ["project_id", "github_pr_number"], name: "index_sessions_on_project_id_and_github_pr_number"
        t.index ["project_id"], name: "index_sessions_on_project_id"
        t.index ["session_id"], name: "index_sessions_on_session_id", unique: true
      end

      create_table "settings", force: :cascade do |t|
        t.string "openai_api_key"
        t.datetime "created_at", null: false
        t.datetime "updated_at", null: false
        t.string "github_username"
      end

      create_table "swarm_templates", force: :cascade do |t|
        t.string "name", null: false
        t.text "description"
        t.json "instance_config"
        t.string "main_instance"
        t.datetime "created_at", null: false
        t.datetime "updated_at", null: false
        t.index ["name"], name: "index_swarm_templates_on_name"
      end

      create_table "version_checkers", force: :cascade do |t|
        t.string "remote_version"
        t.datetime "checked_at"
        t.integer "singleton_guard"
        t.datetime "created_at", null: false
        t.datetime "updated_at", null: false
        t.index ["singleton_guard"], name: "index_version_checkers_on_singleton_guard", unique: true
      end

      add_foreign_key "github_webhook_events", "projects"
      add_foreign_key "github_webhook_processes", "projects"
      add_foreign_key "sessions", "projects"
    end
  end

  def import_data
    puts "Importing data into SQLite..."
    
    data = JSON.parse(File.read(@backup_path))
    
    # Define import order to respect foreign key constraints
    ordered_tables = [
      "settings",
      "version_checkers",
      "instance_templates",
      "swarm_templates",
      "projects",
      "sessions",
      "github_webhook_events",
      "github_webhook_processes"
    ]
    
    ActiveRecord::Base.transaction do
      ordered_tables.each do |table|
        records = data[table] || []
        next if records.empty?
        
        puts "  Importing #{table} (#{records.size} records)..."
        
        model_class = table.classify.constantize rescue nil
        
        if model_class
          # Use model to handle JSON serialization properly
          records.each do |record|
            # Convert JSON strings back to hashes for JSON columns
            json_columns = model_class.columns.select { |c| c.type == :json }.map(&:name)
            
            json_columns.each do |col|
              if record[col].is_a?(String) && record[col].start_with?("{", "[")
                record[col] = JSON.parse(record[col]) rescue record[col]
              end
            end
            
            model_class.create!(record.except("id").merge(id: record["id"]))
          end
        else
          # Fallback to raw SQL for tables without models
          if records.any?
            columns = records.first.keys
            placeholders = columns.map { "?" }.join(", ")
            
            records.each do |record|
              values = columns.map { |col| record[col] }
              ActiveRecord::Base.connection.execute(
                "INSERT INTO #{table} (#{columns.join(', ')}) VALUES (#{placeholders})",
                values
              )
            end
          end
        end
      end
      
      # Reset sequences for each table
      reset_sequences
    end
  end

  def tables_to_export
    excluded_tables = [
      "schema_migrations", 
      "ar_internal_metadata",
      "solid_cable_messages",
      "solid_cache_entries", 
      "solid_queue_blocked_executions",
      "solid_queue_claimed_executions",
      "solid_queue_failed_executions",
      "solid_queue_jobs",
      "solid_queue_pauses",
      "solid_queue_processes",
      "solid_queue_ready_executions",
      "solid_queue_recurring_executions",
      "solid_queue_recurring_tasks",
      "solid_queue_scheduled_executions",
      "solid_queue_semaphores"
    ]
    
    ActiveRecord::Base.connection.tables - excluded_tables
  end

  def reset_sequences
    tables_to_export.each do |table|
      max_id = ActiveRecord::Base.connection.execute("SELECT MAX(id) FROM #{table}").first["MAX(id)"] || 0
      ActiveRecord::Base.connection.execute("UPDATE sqlite_sequence SET seq = #{max_id} WHERE name = '#{table}'")
    end
  rescue
    # SQLite might not have sequences for all tables
  end
end

# Run the migration
if __FILE__ == $0
  begin
    PostgresqlToSqliteMigrator.new.migrate!
  rescue => e
    puts "Migration failed: #{e.message}"
    puts e.backtrace
    exit 1
  end
end